{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "next-word-prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJGqWNroD2m3"
      },
      "source": [
        "from keras.models import Sequential, load_model\n",
        "import pandas as pd\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "def load_obj(name ):\n",
        "    with open(name + '.pkl', 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "    \n",
        "def embed(input):\n",
        "    return encoderModel(input)    "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFsMcQFDD5VU"
      },
      "source": [
        "model = load_model('/content/drive/MyDrive/new/word_embedding.h5')\n",
        "tokenizer = load_obj('/content/drive/MyDrive/new/tokenizer_saved')\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-ctBI13EVLj",
        "outputId": "d63231fc-5114-4a79-f4f4-ee5a263e595c"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "input_text = input().strip().lower()\n",
        "encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
        "pad_encoded = pad_sequences([encoded_text], maxlen=3, truncating='pre')\n",
        "print(encoded_text, pad_encoded)\n",
        "for i in (model.predict(pad_encoded)[0]).argsort()[-3:][::-1]:\n",
        "    pred_word = tokenizer.index_word[i]\n",
        "    print(\"Next word suggestion:\",pred_word)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "example of python\n",
            "[8, 5] [[0 8 5]]\n",
            "Next word suggestion: of\n",
            "Next word suggestion: scientist\n",
            "Next word suggestion: analysis\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ2gH1e2EiqC"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}