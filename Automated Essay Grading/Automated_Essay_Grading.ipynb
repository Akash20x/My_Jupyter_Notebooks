{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Automated Essay Grading",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGeJ9Tlf5gRq",
        "outputId": "07a4336d-4c4a-4cd9-8887-f4add5b29dce"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "#for pre-processing\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "#for model training\n",
        "\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
        "from keras.models import Sequential, load_model, model_from_config\n",
        "import keras.backend as K\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn import ensemble\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import cohen_kappa_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpYqK4V55taJ"
      },
      "source": [
        "test_data = pd.read_csv(\"/content/test_set.tsv\",sep='\\t', encoding='ISO-8859-1')\n",
        "training_data = pd.read_csv(\"/content/training_set_rel3.tsv\",sep='\\t', encoding='ISO-8859-1',\n",
        "                            usecols = ['essay_id', 'essay_set', 'essay','domain1_score']).dropna(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zuqui4TA-msu"
      },
      "source": [
        "scores = training_data['domain1_score']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "UNYVwze36yUS",
        "outputId": "60833c04-7355-457d-e921-8205d47e731c"
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_predictionid</th>\n",
              "      <th>domain2_predictionid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2383</td>\n",
              "      <td>1</td>\n",
              "      <td>I believe that computers have a positive effec...</td>\n",
              "      <td>2383</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2384</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1, I know some problems have came up...</td>\n",
              "      <td>2384</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2385</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear to whom it @MONTH1 concern, Computers are...</td>\n",
              "      <td>2385</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2386</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, @CAPS3 has come to my atte...</td>\n",
              "      <td>2386</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2387</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local newspaper, I think that people have...</td>\n",
              "      <td>2387</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id  essay_set  ... domain1_predictionid  domain2_predictionid\n",
              "0      2383          1  ...                 2383                   NaN\n",
              "1      2384          1  ...                 2384                   NaN\n",
              "2      2385          1  ...                 2385                   NaN\n",
              "3      2386          1  ...                 2386                   NaN\n",
              "4      2387          1  ...                 2387                   NaN\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-Y0cEu8650v",
        "outputId": "5e78880b-73bc-4034-fc20-b88e83fa78a7"
      },
      "source": [
        "test_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4254, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "UyhgfBgk60Vh",
        "outputId": "2b4ef048-a09d-4e44-e259-d0d179a6760a"
      },
      "source": [
        "training_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id  ...  domain1_score\n",
              "0         1  ...              8\n",
              "1         2  ...              9\n",
              "2         3  ...              7\n",
              "3         4  ...             10\n",
              "4         5  ...              8\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIo08YSV64G_",
        "outputId": "5b0c6af3-2282-46b6-d15f-bfd14cc0b9a1"
      },
      "source": [
        "training_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12976, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmt-Jt9u6qqY"
      },
      "source": [
        "test_data.dropna(axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9Cvw9XM6wR0"
      },
      "source": [
        "\n",
        "y = training_data['domain1_score']\n",
        "X = training_data.copy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLIUc7pe7TnY"
      },
      "source": [
        "def essay_to_wordlist(essay_v, remove_stopwords):\n",
        "    #Remove the tagged labels and word tokenize the sentence.\n",
        "    essay_v = re.sub(\"[^a-zA-Z]\", \" \", essay_v)\n",
        "    words = essay_v.lower().split()\n",
        "    if remove_stopwords:\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        words = [w for w in words if not w in stops]\n",
        "    return (words)\n",
        "\n",
        "def essay_to_sentences(essay_v, remove_stopwords):\n",
        "    \"\"\"Sentence tokenize the essay and call essay_to_wordlist() for word tokenization.\"\"\"\n",
        "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "    raw_sentences = tokenizer.tokenize(essay_v.strip())\n",
        "    sentences = []\n",
        "    for raw_sentence in raw_sentences:\n",
        "        if len(raw_sentence) > 0:\n",
        "            sentences.append(essay_to_wordlist(raw_sentence, remove_stopwords))\n",
        "    return sentences\n",
        "\n",
        "def makeFeatureVec(words, model, num_features):\n",
        "    \"\"\"Make ar from the words list of an Essay.\"\"\"\n",
        "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
        "    num_words = 0.\n",
        "    index2word_set = set(model.wv.index2word)\n",
        "    for word in words:\n",
        "        if word in index2word_set:\n",
        "            num_words += 1\n",
        "            featureVec = np.add(featureVec,model[word])        \n",
        "    featureVec = np.divide(featureVec,num_words)\n",
        "    return featureVec\n",
        "\n",
        "def getAvgFeatureVecs(essays, model, num_features):\n",
        "    \"\"\"Main function to generate the word vectors for word2vec model.\"\"\"\n",
        "    counter = 0\n",
        "    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
        "    for essay in essays:\n",
        "        essayFeatureVecs[counter] = makeFeatureVec(essay, model, num_features)\n",
        "        counter = counter + 1\n",
        "    return essayFeatureVecs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poBfr2pm7b1c"
      },
      "source": [
        "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
        "from keras.models import Sequential, load_model, model_from_config\n",
        "import keras.backend as K\n",
        "\n",
        "def get_model():\n",
        "    \"\"\"Define the model.\"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
        "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='relu'))\n",
        "\n",
        "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3T0MKXk7gti",
        "outputId": "3c5a5dcf-a310-4e13-f9e5-8a201e883717"
      },
      "source": [
        "cv = KFold(n_splits = 5, shuffle = True)\n",
        "results = []\n",
        "y_pred_list = []\n",
        "\n",
        "count = 1\n",
        "for traincv, testcv in cv.split(X):\n",
        "    print(\"\\n--------Fold {}--------\\n\".format(count))\n",
        "    X_test, X_train, y_test, y_train = X.iloc[testcv], X.iloc[traincv], y.iloc[testcv], y.iloc[traincv]\n",
        "    \n",
        "    train_essays = X_train['essay']\n",
        "    test_essays = X_test['essay']\n",
        "    \n",
        "    sentences = []\n",
        "    \n",
        "    for essay in train_essays:\n",
        "            # Obtaining all sentences from the training essays.\n",
        "            sentences += essay_to_sentences(essay, remove_stopwords = True)\n",
        "            \n",
        "    # Initializing variables for word2vec model.\n",
        "    num_features = 300\n",
        "    min_word_count = 40\n",
        "    num_workers = 8\n",
        "    context = 10\n",
        "    downsampling = 1e-3\n",
        "\n",
        "    \n",
        "    print(\"Training Word2Vec Model...\")\n",
        "    model = Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
        "\n",
        "    model.init_sims(replace=True)\n",
        "    model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)\n",
        "\n",
        "    clean_train_essays = []\n",
        "    \n",
        "    # Generate training and testing data word vectors.\n",
        "    for essay_v in train_essays:\n",
        "        clean_train_essays.append(essay_to_wordlist(essay_v, remove_stopwords=True))\n",
        "    trainDataVecs = getAvgFeatureVecs(clean_train_essays, model, num_features)\n",
        "    \n",
        "    clean_test_essays = []\n",
        "    for essay_v in test_essays:\n",
        "        clean_test_essays.append(essay_to_wordlist( essay_v, remove_stopwords=True ))\n",
        "    testDataVecs = getAvgFeatureVecs( clean_test_essays, model, num_features )\n",
        "    \n",
        "    trainDataVecs = np.array(trainDataVecs)\n",
        "    testDataVecs = np.array(testDataVecs)\n",
        "    # Reshaping train and test vectors to 3 dimensions. (1 represnts one timestep)\n",
        "    trainDataVecs = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n",
        "    testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
        "    \n",
        "    lstm_model = get_model()\n",
        "    lstm_model.fit(trainDataVecs, y_train, batch_size=64, epochs=2)\n",
        "    #lstm_model.load_weights('./model_weights/final_lstm.h5')\n",
        "    y_pred = lstm_model.predict(testDataVecs)\n",
        "    \n",
        "    # Save any one of the 5 models.\n",
        "    if count == 5:\n",
        "         lstm_model.save_weights('final_lstm.h5')\n",
        "    \n",
        "    # Round y_pred to the nearest integer.\n",
        "    y_pred = np.around(y_pred)\n",
        "    \n",
        "    # Evaluate the model on the evaluation metric. \"Quadratic mean averaged Kappa\"\n",
        "    result = cohen_kappa_score(y_test.values,y_pred,weights='quadratic')\n",
        "    print(\"Kappa Score: {}\".format(result))\n",
        "    results.append(result)\n",
        "\n",
        "    count += 1    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--------Fold 1--------\n",
            "\n",
            "Training Word2Vec Model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 1, 300)            721200    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 814,705\n",
            "Trainable params: 814,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 27s 12ms/step - loss: 89.3029 - mae: 5.2541\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 42.8564 - mae: 3.6634\n",
            "Kappa Score: 0.7247101913984099\n",
            "\n",
            "--------Fold 2--------\n",
            "\n",
            "Training Word2Vec Model...\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 1, 300)            721200    \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 814,705\n",
            "Trainable params: 814,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 7s 12ms/step - loss: 89.3625 - mae: 5.2007\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 42.0730 - mae: 3.5683\n",
            "Kappa Score: 0.7414075049792751\n",
            "\n",
            "--------Fold 3--------\n",
            "\n",
            "Training Word2Vec Model...\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_4 (LSTM)                (None, 1, 300)            721200    \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 814,705\n",
            "Trainable params: 814,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 8s 13ms/step - loss: 79.3181 - mae: 4.9611\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 39.2139 - mae: 3.5140\n",
            "Kappa Score: 0.7320065389449628\n",
            "\n",
            "--------Fold 4--------\n",
            "\n",
            "Training Word2Vec Model...\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_6 (LSTM)                (None, 1, 300)            721200    \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 814,705\n",
            "Trainable params: 814,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 7s 12ms/step - loss: 85.7830 - mae: 5.1530\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 12ms/step - loss: 48.0523 - mae: 3.8151\n",
            "Kappa Score: 0.7335195203918724\n",
            "\n",
            "--------Fold 5--------\n",
            "\n",
            "Training Word2Vec Model...\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_8 (LSTM)                (None, 1, 300)            721200    \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 814,705\n",
            "Trainable params: 814,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "163/163 [==============================] - 7s 12ms/step - loss: 81.6253 - mae: 4.9873\n",
            "Epoch 2/2\n",
            "163/163 [==============================] - 2s 13ms/step - loss: 42.8192 - mae: 3.6402\n",
            "Kappa Score: 0.7658808935855221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uVCRjAG-CMF",
        "outputId": "8d54c7d8-fa50-4a8e-d604-0a73afe6dd84"
      },
      "source": [
        "print(\"Average Kappa score after a 5-fold cross validation: \",np.around(np.array(results).mean(),decimals=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Kappa score after a 5-fold cross validation:  0.7395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IVKdy1d7j2q",
        "outputId": "dbc5ee3d-0fd6-410c-f504-e907a1b4b901"
      },
      "source": [
        "# Splitting dataset into training and test set and generating word embeddings for other models other than\n",
        "# neural networks\n",
        "\n",
        "indep_train, indep_test, dep_train, dep_test = train_test_split(X, scores, test_size = 0.25)\n",
        "\n",
        "train_essays2 = indep_train['essay']\n",
        "test_essays2 = indep_test['essay']\n",
        "    \n",
        "sentences2 = []\n",
        "\n",
        "\n",
        "for essay2 in train_essays2:\n",
        "            # Obtaining all sentences from the training set of essays.\n",
        "            sentences2 += essay_to_sentences(essay2,remove_stopwords = True)\n",
        "            \n",
        "# Initializing variables for word2vec model.\n",
        "num_features = 300 \n",
        "min_word_count = 40\n",
        "num_workers = 4\n",
        "context = 10\n",
        "downsampling = 1e-3\n",
        "\n",
        "print(\"Training Word2Vec Model...\")\n",
        "model = Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
        "\n",
        "model.init_sims(replace=True)\n",
        "model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)\n",
        "\n",
        "clean_train_essays2 = []\n",
        "    \n",
        "# Generate training and testing data word vectors.\n",
        "for essay_text2 in train_essays2:\n",
        "    clean_train_essays2.append(essay_to_wordlist(essay_text2,remove_stopwords = True))\n",
        "trainDataVecs2 = getAvgFeatureVecs(clean_train_essays2, model, num_features)\n",
        "    \n",
        "clean_test_essays2 = []\n",
        "for essay_text2 in test_essays2:\n",
        "    clean_test_essays2.append(essay_to_wordlist(essay_text2,remove_stopwords = True))\n",
        "testDataVecs2 = getAvgFeatureVecs(clean_test_essays2, model, num_features)\n",
        "    \n",
        "trainDataVecs2 = np.array(trainDataVecs2)\n",
        "testDataVecs2 = np.array(testDataVecs2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Word2Vec Model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCDipn8i9zee",
        "outputId": "6d8c718d-eec2-4964-b722-f15e1df786f0"
      },
      "source": [
        "# Generating scores using Linear Regression Model\n",
        "\n",
        "linear_regressor = LinearRegression()\n",
        "\n",
        "linear_regressor.fit(trainDataVecs2, dep_train)\n",
        "\n",
        "dep_pred = linear_regressor.predict(testDataVecs2)\n",
        "\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\" % mean_squared_error(dep_test, dep_pred))\n",
        "\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print('Variance score: %.2f' % explained_variance_score(dep_test,dep_pred))\n",
        "\n",
        "#print('Cohen\\'s kappa score: %.2f' % cohen_kappa_score(dep_pred, dep_test))\n",
        "print(\"Kappa Score: {0:.2f}\".format(cohen_kappa_score(dep_test.values,np.around(dep_pred),weights='quadratic')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean squared error: 21.37\n",
            "Variance score: 0.74\n",
            "Kappa Score: 0.85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RD9X4cplAJm3",
        "outputId": "05991bd7-238a-48d6-c793-4cf0befeb6a8"
      },
      "source": [
        "#Generating scores using Gradient Boosting regressor\n",
        "\n",
        "'''from sklearn.model_selection import GridSearchCV\n",
        "params = {'n_estimators':[100, 1000], 'max_depth':[2], 'min_samples_split': [2],\n",
        "          'learning_rate':[3, 1, 0.1, 0.3], 'loss': ['ls']}\n",
        "\n",
        "gbr = ensemble.GradientBoostingRegressor()\n",
        "\n",
        "grid = GridSearchCV(gbr, params)\n",
        "grid.fit(trainDataVecs2, dep_train)\n",
        "\n",
        "y_pred = grid.predict(testDataVecs2)\n",
        "\n",
        "# summarize the results of the grid search\n",
        "print(grid.best_score_)\n",
        "print(grid.best_estimator_)'''\n",
        "\n",
        "#USING THE PARAMS FOUND OUT USING GRID SEARCH CV\n",
        "gbr = ensemble.GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
        "             learning_rate=0.1, loss='ls', max_depth=2, max_features=None,\n",
        "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
        "             min_impurity_split=None, min_samples_leaf=1,\n",
        "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
        "             n_estimators=1000, presort='auto', random_state=None,\n",
        "             subsample=1.0, verbose=0, warm_start=False)\n",
        "gbr.fit(trainDataVecs2, dep_train)\n",
        "dep_pred = gbr.predict(testDataVecs2)\n",
        "\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\" % mean_squared_error(dep_test, dep_pred))\n",
        "\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print('Variance score: %.2f' % explained_variance_score(dep_test,dep_pred))\n",
        "\n",
        "print(\"Kappa Score: {0:.2f}\".format(cohen_kappa_score(dep_test.values,np.around(dep_pred),weights='quadratic')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:1342: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mean squared error: 8.44\n",
            "Variance score: 0.90\n",
            "Kappa Score: 0.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_K6BGP2OAraH",
        "outputId": "0f287f6a-a9a6-4c6a-b104-b3b1e1bf5347"
      },
      "source": [
        "# Generating scores using Support Vector Regression\n",
        "svr = SVR()\n",
        "\n",
        "'''parameters = {'kernel':['linear', 'rbf'], 'C':[1, 100], 'gamma':[0.1, 0.001]}\n",
        "\n",
        "grid = GridSearchCV(svr, parameters)\n",
        "grid.fit(trainDataVecs2, dep_train)\n",
        "\n",
        "y_pred = grid.predict(testDataVecs2)\n",
        "\n",
        "# summarize the results of the grid search\n",
        "print(grid.best_score_)\n",
        "print(grid.best_estimator_)'''\n",
        "\n",
        "#USING THE PARAMS FOUND OUT USING GRID SEARCH CV\n",
        "svr = SVR(C=100, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.1,kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
        "svr.fit(trainDataVecs2, dep_train)\n",
        "dep_pred = svr.predict(testDataVecs2)\n",
        "\n",
        "\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\" % mean_squared_error(dep_test, dep_pred))\n",
        "\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print('Variance score: %.2f' % explained_variance_score(dep_test,dep_pred))\n",
        "\n",
        "#Cohen's Kappa score\n",
        "print(\"Kappa Score: {0:.2f}\".format(cohen_kappa_score(dep_test.values,np.around(dep_pred),weights='quadratic')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean squared error: 39.44\n",
            "Variance score: 0.53\n",
            "Kappa Score: 0.64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzwT3hDvBIxU",
        "outputId": "2c8c9e9e-ef5d-43c1-dd39-993279143fbd"
      },
      "source": [
        "# Generating scores using XGBClassifier\n",
        "from xgboost import XGBClassifier\n",
        "xgb=XGBClassifier(colsample_bytree=0.4,gamma=0,learning_rate=0.01,max_depth=4,min_child_weight=0.5,n_estimators=100,                                                                    reg_alpha=0.75,reg_lambda=0.45,\n",
        "                 subsample=0.6,seed=42)\n",
        "xgb.fit(trainDataVecs2, dep_train)\n",
        "dep_pred = xgb.predict(testDataVecs2)\n",
        "\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\" % mean_squared_error(dep_test, dep_pred))\n",
        "\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print('Variance score: %.2f' % explained_variance_score(dep_test,dep_pred))\n",
        "\n",
        "#print('Cohen\\'s kappa score: %.2f' % cohen_kappa_score(dep_pred, dep_test))\n",
        "print(\"Kappa Score: {0:.2f}\".format(cohen_kappa_score(dep_test.values,np.around(dep_pred),weights='quadratic')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean squared error: 15.78\n",
            "Variance score: 0.81\n",
            "Kappa Score: 0.90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auYVWNYdDkTS",
        "outputId": "11718b7e-5f33-4816-d725-c18e6e4a54f5"
      },
      "source": [
        "# Generating scores using Logistic Regression\n",
        "lr = LogisticRegression(random_state=1, max_iter=1000)\n",
        "lr.fit(trainDataVecs2, dep_train)\n",
        "dep_pred = lr.predict(testDataVecs2)\n",
        "\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\" % mean_squared_error(dep_test, dep_pred))\n",
        "\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print('Variance score: %.2f' % explained_variance_score(dep_test,dep_pred))\n",
        "\n",
        "#print('Cohen\\'s kappa score: %.2f' % cohen_kappa_score(dep_pred, dep_test))\n",
        "print(\"Kappa Score: {0:.2f}\".format(cohen_kappa_score(dep_test.values,np.around(dep_pred),weights='quadratic')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean squared error: 52.54\n",
            "Variance score: 0.38\n",
            "Kappa Score: 0.57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcV-obvrH8ES",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39847bb8-98ad-4083-9108-e107e7461260"
      },
      "source": [
        "# Generating scores using K-Nearest Neighbor\n",
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "knn.fit(trainDataVecs2, dep_train)\n",
        "dep_pred = knn.predict(testDataVecs2)\n",
        "\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\" % mean_squared_error(dep_test, dep_pred))\n",
        "\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print('Variance score: %.2f' % explained_variance_score(dep_test,dep_pred))\n",
        "\n",
        "#print('Cohen\\'s kappa score: %.2f' % cohen_kappa_score(dep_pred, dep_test))\n",
        "print(\"Kappa Score: {0:.2f}\".format(cohen_kappa_score(dep_test.values,np.around(dep_pred),weights='quadratic')))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean squared error: 17.52\n",
            "Variance score: 0.79\n",
            "Kappa Score: 0.90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1w0mbbAIOEw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d7ffd26-7381-45bc-b801-39ac0810c65d"
      },
      "source": [
        "# Generating scores using Desion Tree Classifier\n",
        "dt = DecisionTreeClassifier(criterion = 'entropy',random_state=0,max_depth = 30)\n",
        "dt.fit(trainDataVecs2, dep_train)\n",
        "dep_pred = dt.predict(testDataVecs2)\n",
        "\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\" % mean_squared_error(dep_test, dep_pred))\n",
        "\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print('Variance score: %.2f' % explained_variance_score(dep_test,dep_pred))\n",
        "\n",
        "#print('Cohen\\'s kappa score: %.2f' % cohen_kappa_score(dep_pred, dep_test))\n",
        "print(\"Kappa Score: {0:.2f}\".format(cohen_kappa_score(dep_test.values,np.around(dep_pred),weights='quadratic')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean squared error: 20.32\n",
            "Variance score: 0.75\n",
            "Kappa Score: 0.87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MW8TGHBIbbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74806295-9c7b-413d-aee3-3f0826ff3194"
      },
      "source": [
        "# Generating scores using Random Forest Classifier\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=0,max_depth=12)\n",
        "rf.fit(trainDataVecs2, dep_train)\n",
        "dep_pred = rf.predict(testDataVecs2)\n",
        "\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\" % mean_squared_error(dep_test, dep_pred))\n",
        "\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print('Variance score: %.2f' % explained_variance_score(dep_test,dep_pred))\n",
        "\n",
        "#print('Cohen\\'s kappa score: %.2f' % cohen_kappa_score(dep_pred, dep_test))\n",
        "print(\"Kappa Score: {0:.2f}\".format(cohen_kappa_score(dep_test.values,np.around(dep_pred),weights='quadratic')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean squared error: 9.48\n",
            "Variance score: 0.88\n",
            "Kappa Score: 0.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfIe5758PeG_"
      },
      "source": [
        "* Gradient Boosting regressor gives highest cohen kappa score (0.95) \n",
        "* We made our final prediction with Gradient Boosting Regressor Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkAilMekTwOi"
      },
      "source": [
        "## Prediction by best Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0b7vb8FTqD4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a43af8a-7bc6-4a86-aa02-58c05be9501b"
      },
      "source": [
        "gbr = ensemble.GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
        "             learning_rate=0.1, loss='ls', max_depth=2, max_features=None,\n",
        "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
        "             min_impurity_split=None, min_samples_leaf=1,\n",
        "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
        "             n_estimators=1000, presort='auto', random_state=None,\n",
        "             subsample=1.0, verbose=0, warm_start=False)\n",
        "gbr.fit(trainDataVecs2, dep_train)\n",
        "predicted_scores = gbr.predict(testDataVecs2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:1342: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6_0WOLVMLwL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "0b11bf76-70d2-4a9f-8e17-086f65de4625"
      },
      "source": [
        "predicted_score = predicted_scores\n",
        "# predicted_score = pd.Series([score for sublist in predicted_scores for score in sublist])\n",
        "predicted_score=pd.DataFrame(predicted_score,columns=['Predicted_Score']).round()\n",
        "predicted_score.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Predicted_Score\n",
              "0              3.0\n",
              "1              2.0\n",
              "2              3.0\n",
              "3              2.0\n",
              "4              7.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZgNaf5PMOEu"
      },
      "source": [
        "final_scores = pd.concat([test_data, predicted_score], axis = 1).rename(columns = {0:\"predicted_score\"})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnaKTQw2MOGW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "ed095396-163a-4bab-aaf2-3829e3b0b8d8"
      },
      "source": [
        "final_scores.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_predictionid</th>\n",
              "      <th>Predicted_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2383</td>\n",
              "      <td>1</td>\n",
              "      <td>I believe that computers have a positive effec...</td>\n",
              "      <td>2383</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2384</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1, I know some problems have came up...</td>\n",
              "      <td>2384</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2385</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear to whom it @MONTH1 concern, Computers are...</td>\n",
              "      <td>2385</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2386</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, @CAPS3 has come to my atte...</td>\n",
              "      <td>2386</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2387</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local newspaper, I think that people have...</td>\n",
              "      <td>2387</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id  essay_set  ... domain1_predictionid  Predicted_Score\n",
              "0      2383          1  ...                 2383              3.0\n",
              "1      2384          1  ...                 2384              2.0\n",
              "2      2385          1  ...                 2385              3.0\n",
              "3      2386          1  ...                 2386              2.0\n",
              "4      2387          1  ...                 2387              7.0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    }
  ]
}